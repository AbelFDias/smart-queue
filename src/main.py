"""
SMART QUEUE - Sistema de Gest√£o de Filas com Vis√£o Computacional
Detec√ß√£o de pessoas usando YOLOv8 local (sem necessidade de API/internet!)

Tecnologias:
- YOLOv8 (ultralytics) para detec√ß√£o de pessoas
- OpenCV para captura e processamento de v√≠deo
- YAML para configura√ß√£o

Autor: Abel Dias e Sim√£o Marcos
"""

import cv2
import yaml
import time
from pathlib import Path
from ultralytics.models.yolo import YOLO
from vision import detect_people, draw_detections, draw_info
from tracker import SimpleTracker

# ============================================
# CONFIGURA√á√ÉO
# ============================================

# Diret√≥rio raiz do projeto
ROOT_DIR = Path(__file__).parent.parent

# Carregar configura√ß√£o do ficheiro YAML
config_path = ROOT_DIR / 'config' / 'config.yaml'
with open(config_path, 'r') as f:
    CONFIG = yaml.safe_load(f)

# Extrair configura√ß√µes
VIDEO_SOURCE = CONFIG.get('video_source', 0)
PROCESS_EVERY_N = CONFIG.get('process_every_n_frames', 3)
CONFIDENCE = CONFIG.get('confidence_threshold', 0.5)
YOLO_MODEL = CONFIG.get('yolo_model', 'yolov8n.pt')

# Par√¢metros (f√°ceis de ajustar)
LINE_COLOR = (0, 0, 255)  # BGR (vermelho)
LINE_THICKNESS = 2

# Tracking e contagem
TRACK_MATCH_RADIUS_PX = 60  # raio para associar centroides entre frames
TRACK_TTL = 6               # ciclos de dete√ß√£o at√© expirar track
LINE_BAND_PX = 100          # banda de avalia√ß√£o √† volta da linha
DIRECTION = 'left_to_right' # dire√ß√£o v√°lida para contar

# Carregar modelo YOLO
# Na primeira execu√ß√£o faz download autom√°tico (~6MB para nano)
print("üîÑ A carregar modelo YOLO...")

# Resolver caminho do modelo (suporta caminho relativo √† raiz do projeto)
_model_cfg_path = Path(YOLO_MODEL)
_resolved_model_path = _model_cfg_path if _model_cfg_path.is_absolute() else (ROOT_DIR / _model_cfg_path)

if _resolved_model_path.exists():
    MODEL = YOLO(str(_resolved_model_path))
    print(f"‚úÖ Modelo carregado de: {_resolved_model_path}")
else:
    # Fallback: usar identificador do modelo (Ultralytics faz download se necess√°rio)
    print(f"‚ÑπÔ∏è  Modelo local n√£o encontrado em '{_resolved_model_path}'. A tentar carregar '{YOLO_MODEL}'.")
    MODEL = YOLO(YOLO_MODEL)
    print("‚úÖ Modelo carregado com sucesso (Ultralytics)")

# ============================================
# FUN√á√ïES
# ============================================

def draw_info(frame, fps, num_people):
    # esta fun√ß√£o agora √© importada de vision.py; manter stub se necess√°rio
    return draw_info(frame, fps, num_people)


# ============================================
# LINE-CROSSING HELPERS
# ============================================

def _sign(x: float, eps: float = 1e-3) -> int:
    if x > eps:
        return 1
    if x < -eps:
        return -1
    return 0


def _point_side(p, a, b) -> float:
    # cross((b - a), (p - a))
    return (b[0] - a[0]) * (p[1] - a[1]) - (b[1] - a[1]) * (p[0] - a[0])


def _crossed_line(prev_p, curr_p, a, b) -> bool:
    s1 = _sign(_point_side(prev_p, a, b))
    s2 = _sign(_point_side(curr_p, a, b))
    return s1 != 0 and s2 != 0 and s1 != s2


# ============================================
# MAIN
# ============================================

def main():
    """Loop principal do sistema de detec√ß√£o."""
    print("=" * 70)
    print("  üéØ SMART QUEUE - Sistema de Gest√£o de Filas")
    print("  üìπ Detec√ß√£o local com YOLOv8 (sem necessidade de internet!)")
    print("=" * 70)
    print()
    
    # Abrir fonte de v√≠deo
    print(f"üìπ A abrir fonte de v√≠deo: {VIDEO_SOURCE}")
    cap = cv2.VideoCapture(VIDEO_SOURCE)
    
    if not cap.isOpened():
        print(f"‚ùå ERRO: N√£o foi poss√≠vel abrir a fonte de v√≠deo: {VIDEO_SOURCE}")
        print("\nüí° Dicas:")
        print("  - Verifica se a webcam est√° conectada")
        print("  - Tenta mudar video_source no config.yaml (0, 1, 2...)")
        print("  - Se usas Iriun, verifica se a app est√° a correr")
        return
    
    print(f"‚úÖ Fonte de v√≠deo aberta com sucesso!")
    print()
    print("‚öôÔ∏è  Configura√ß√£o:")
    print(f"  - Modelo: {YOLO_MODEL}")
    print(f"  - Processar: 1 em cada {PROCESS_EVERY_N} frames")
    print(f"  - Confian√ßa m√≠nima: {CONFIDENCE:.0%}")
    print()
    print("üéÆ Controlos:")
    print("  Q - Sair")
    print()
    print("=" * 70)
    print()
    
    # Estado
    frame_counter = 0
    last_detections = []
    fps = 0
    total_frames = 0
    start_time = time.time()
    # Estado para contagem por linha
    tracker = SimpleTracker(match_radius_px=TRACK_MATCH_RADIUS_PX, ttl=TRACK_TTL)
    entry_count = 0
    # Linha vertical (fila esquerda ‚Üí direita), inicializa com base no tamanho do frame
    line_a = None  # (x, y)
    line_b = None  # (x, y)
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Erro ao ler frame")
                break

            # Inicializar linha vertical ap√≥s obter dimens√µes do frame
            if line_a is None:
                H, W = frame.shape[:2]
                x_mid = W // 2
                line_a = (x_mid, 0)
                line_b = (x_mid, H)
            
            total_frames += 1
            frame_counter += 1
            
            # Calcular FPS
            elapsed = time.time() - start_time
            if elapsed > 0:
                fps = total_frames / elapsed
            
            # Fazer detec√ß√£o a cada N frames (para otimizar performance)
            if frame_counter >= PROCESS_EVERY_N:
                frame_counter = 0
                
                try:
                    last_detections = detect_people(MODEL, frame, CONFIDENCE)
                    num = len(last_detections)
                    print(f"üìä [Frame {total_frames}] Detectadas {num} pessoa(s) | FPS: {fps:.1f}")

                    # Calcular centroides atuais
                    curr_centroids = [
                        ((d['x1'] + d['x2']) // 2, (d['y1'] + d['y2']) // 2)
                        for d in last_detections
                    ]

                    # Atualizar tracker e obter pares (track_id, prev_c, curr_c)
                    matches = tracker.update(curr_centroids)

                    # Contagem com filtro de dire√ß√£o (left -> right) e banda
                    x_line = line_a[0]
                    for _, prev_c, curr_c in matches:
                        # banda em torno da linha
                        if (abs(prev_c[0] - x_line) > LINE_BAND_PX and
                                abs(curr_c[0] - x_line) > LINE_BAND_PX):
                            continue
                        # cruzamento geom√©trico
                        if _crossed_line(prev_c, curr_c, line_a, line_b):
                            # dire√ß√£o v√°lida
                            if DIRECTION == 'left_to_right' and curr_c[0] > prev_c[0]:
                                entry_count += 1
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro na detec√ß√£o: {e}")
                    last_detections = []
            
            # Desenhar
            if last_detections:
                frame = draw_detections(frame, last_detections)
            
            frame = draw_info(frame, fps, len(last_detections))

            # Desenhar linha de contagem (ap√≥s overlay para ficar vis√≠vel)
            if line_a is not None and line_b is not None:
                cv2.line(frame, line_a, line_b, LINE_COLOR, LINE_THICKNESS)

            # Mostrar total de entradas (no HUD)
            cv2.putText(frame, f"Entradas: {entry_count}", (20, 85),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Mostrar resultado
            cv2.imshow('Smart Queue - Sistema de Detec√ß√£o', frame)
            
            # Verificar tecla pressionada
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == ord('Q'):
                print("\nüõë A encerrar...")
                break
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrompido pelo utilizador (Ctrl+C)")
    
    except Exception as e:
        print(f"\n‚ùå Erro fatal: {e}")
    
    finally:
        # Libertar recursos
        cap.release()
        cv2.destroyAllWindows()
        
        # Estat√≠sticas finais
        elapsed_time = time.time() - start_time
        print()
        print("=" * 70)
        print("üìä Estat√≠sticas da sess√£o:")
        print(f"  - Total de frames processados: {total_frames}")
        print(f"  - FPS m√©dio: {fps:.1f}")
        print(f"  - Tempo total: {elapsed_time:.1f}s")
        print("=" * 70)
        print("‚úÖ Sistema encerrado com sucesso!")


if __name__ == "__main__":
    main()
