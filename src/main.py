"""
SMART QUEUE - Sistema de Gest√£o de Filas com Vis√£o Computacional
Detec√ß√£o de pessoas usando YOLOv8 local (sem necessidade de API/internet!)

Tecnologias:
- YOLOv8 (ultralytics) para detec√ß√£o de pessoas
- OpenCV para captura e processamento de v√≠deo
- YAML para configura√ß√£o

Autor: Abel Dias e Sim√£o Marcos
"""

import cv2
import yaml
import time
from pathlib import Path
from ultralytics.models.yolo import YOLO

# ============================================
# CONFIGURA√á√ÉO
# ============================================

# Diret√≥rio raiz do projeto
ROOT_DIR = Path(__file__).parent.parent

# Carregar configura√ß√£o do ficheiro YAML
config_path = ROOT_DIR / 'config' / 'config.yaml'
with open(config_path, 'r') as f:
    CONFIG = yaml.safe_load(f)

# Extrair configura√ß√µes
VIDEO_SOURCE = CONFIG.get('video_source', 0)
PROCESS_EVERY_N = CONFIG.get('process_every_n_frames', 3)
CONFIDENCE = CONFIG.get('confidence_threshold', 0.5)
YOLO_MODEL = CONFIG.get('yolo_model', 'yolov8n.pt')

# Carregar modelo YOLO
# Na primeira execu√ß√£o faz download autom√°tico (~6MB para nano)
print("üîÑ A carregar modelo YOLO...")

# Resolver caminho do modelo (suporta caminho relativo √† raiz do projeto)
_model_cfg_path = Path(YOLO_MODEL)
_resolved_model_path = _model_cfg_path if _model_cfg_path.is_absolute() else (ROOT_DIR / _model_cfg_path)

if _resolved_model_path.exists():
    MODEL = YOLO(str(_resolved_model_path))
    print(f"‚úÖ Modelo carregado de: {_resolved_model_path}")
else:
    # Fallback: usar identificador do modelo (Ultralytics faz download se necess√°rio)
    print(f"‚ÑπÔ∏è  Modelo local n√£o encontrado em '{_resolved_model_path}'. A tentar carregar '{YOLO_MODEL}'.")
    MODEL = YOLO(YOLO_MODEL)
    print("‚úÖ Modelo carregado com sucesso (Ultralytics)")

# ============================================
# FUN√á√ïES
# ============================================

def detect_people(frame):
    """
    Detecta pessoas num frame usando YOLOv8 local.
    
    Args:
        frame: Frame numpy array (BGR) do OpenCV
    
    Returns:
        Lista de dicion√°rios com detec√ß√µes:
        [{
            'x1': int, 'y1': int,  # Canto superior esquerdo
            'x2': int, 'y2': int,  # Canto inferior direito
            'confidence': float    # Confian√ßa da detec√ß√£o (0-1)
        }, ...]
    """
    # Infer√™ncia YOLO
    # classes=[0] = apenas pessoas (classe 0 do COCO dataset)
    # verbose=False = sem prints no terminal
    results = MODEL(frame, conf=CONFIDENCE, classes=[0], verbose=False)
    
    # Extrair bounding boxes
    detections = []
    for result in results:
        boxes = result.boxes
        for box in boxes:
            # Coordenadas do bounding box
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = float(box.conf[0])
            
            detections.append({
                'x1': int(x1),
                'y1': int(y1),
                'x2': int(x2),
                'y2': int(y2),
                'confidence': conf
            })
    
    return detections


def draw_detections(frame, detections):
    """
    Desenha bounding boxes sobre as detec√ß√µes de pessoas.
    
    Args:
        frame: Frame onde desenhar
        detections: Lista de detec√ß√µes da fun√ß√£o detect_people()
    
    Returns:
        Frame com as detec√ß√µes desenhadas
    """
    for det in detections:
        x1, y1 = det['x1'], det['y1']
        x2, y2 = det['x2'], det['y2']
        conf = det['confidence']
        
        # Desenhar ret√¢ngulo verde em volta da pessoa
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # Label com confian√ßa
        label = f"Pessoa: {conf:.0%}"
        
        # Fundo para o texto (melhor legibilidade)
        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
        label_w, label_h = label_size
        cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w, y1), (0, 255, 0), -1)
        
        # Texto
        cv2.putText(frame, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
    
    return frame


def draw_info(frame, fps, num_people):
    """
    Desenha painel de informa√ß√µes no canto superior esquerdo.
    
    Args:
        frame: Frame onde desenhar
        fps: FPS atual
        num_people: N√∫mero de pessoas detectadas
    
    Returns:
        Frame com overlay de informa√ß√µes
    """
    # Criar fundo semi-transparente
    overlay = frame.copy()
    cv2.rectangle(overlay, (10, 10), (280, 85), (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
    
    # Informa√ß√µes
    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 35),
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.putText(frame, f"Pessoas detectadas: {num_people}", (20, 60),
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    return frame


# ============================================
# MAIN
# ============================================

def main():
    """Loop principal do sistema de detec√ß√£o."""
    print("=" * 70)
    print("  üéØ SMART QUEUE - Sistema de Gest√£o de Filas")
    print("  üìπ Detec√ß√£o local com YOLOv8 (sem necessidade de internet!)")
    print("=" * 70)
    print()
    
    # Abrir fonte de v√≠deo
    print(f"üìπ A abrir fonte de v√≠deo: {VIDEO_SOURCE}")
    cap = cv2.VideoCapture(VIDEO_SOURCE)
    
    if not cap.isOpened():
        print(f"‚ùå ERRO: N√£o foi poss√≠vel abrir a fonte de v√≠deo: {VIDEO_SOURCE}")
        print("\nüí° Dicas:")
        print("  - Verifica se a webcam est√° conectada")
        print("  - Tenta mudar video_source no config.yaml (0, 1, 2...)")
        print("  - Se usas Iriun, verifica se a app est√° a correr")
        return
    
    print(f"‚úÖ Fonte de v√≠deo aberta com sucesso!")
    print()
    print("‚öôÔ∏è  Configura√ß√£o:")
    print(f"  - Modelo: {YOLO_MODEL}")
    print(f"  - Processar: 1 em cada {PROCESS_EVERY_N} frames")
    print(f"  - Confian√ßa m√≠nima: {CONFIDENCE:.0%}")
    print()
    print("üéÆ Controlos:")
    print("  Q - Sair")
    print()
    print("=" * 70)
    print()
    
    # Estado
    frame_counter = 0
    last_detections = []
    fps = 0
    total_frames = 0
    start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Erro ao ler frame")
                break
            
            total_frames += 1
            frame_counter += 1
            
            # Calcular FPS
            elapsed = time.time() - start_time
            if elapsed > 0:
                fps = total_frames / elapsed
            
            # Fazer detec√ß√£o a cada N frames (para otimizar performance)
            if frame_counter >= PROCESS_EVERY_N:
                frame_counter = 0
                
                try:
                    last_detections = detect_people(frame)
                    num = len(last_detections)
                    print(f"üìä [Frame {total_frames}] Detectadas {num} pessoa(s) | FPS: {fps:.1f}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro na detec√ß√£o: {e}")
                    last_detections = []
            
            # Desenhar
            if last_detections:
                frame = draw_detections(frame, last_detections)
            
            frame = draw_info(frame, fps, len(last_detections))
            
            # Mostrar resultado
            cv2.imshow('Smart Queue - Sistema de Detec√ß√£o', frame)
            
            # Verificar tecla pressionada
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == ord('Q'):
                print("\nüõë A encerrar...")
                break
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrompido pelo utilizador (Ctrl+C)")
    
    except Exception as e:
        print(f"\n‚ùå Erro fatal: {e}")
    
    finally:
        # Libertar recursos
        cap.release()
        cv2.destroyAllWindows()
        
        # Estat√≠sticas finais
        elapsed_time = time.time() - start_time
        print()
        print("=" * 70)
        print("üìä Estat√≠sticas da sess√£o:")
        print(f"  - Total de frames processados: {total_frames}")
        print(f"  - FPS m√©dio: {fps:.1f}")
        print(f"  - Tempo total: {elapsed_time:.1f}s")
        print("=" * 70)
        print("‚úÖ Sistema encerrado com sucesso!")


if __name__ == "__main__":
    main()
